```shell
                    _   .-')                          .-') _               .-') _     ('-.
                   ( '.( OO )_                       ( OO ) )             (  OO) )  _(  OO)
                    ,--.   ,--.),--.             ,--./ ,--,'  .-'),-----. /     '._(,------.
                    |   `.'   | |  |.-')         |   \ |  |\ ( OO'  .-.  '|'--...__)|  .---'
                    |         | |  | OO )        |    \|  | )/   |  | |  |'--.  .--'|  |
                    |  |'.'|  | |  |`-' |{}_O--)(|  .     |/ \_) |  |\|  |   |  |  (|  '--.
                    |  |   |  |(|  '---.'(OO  )_ |  |\    |    \ |  | |  |   |  |   |  .--'
                    |  |   |  | |      |         |  | \   |     `'  '-'  '   |  |   |  `---.
                    `--'   `--' `------'         `--'  `--'       `-----'    `--'   `------'
```

# <p align="center">ML-NOTE</p>

<p align="center">
 <a href="https://github.com/yhangf/ML-NOTE/blob/master/LICENSE">
        <img src="https://img.shields.io/cocoapods/l/EFQRCode.svg?style=flat">
        </a>
 <a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">
        <img src="https://img.shields.io/badge/ML-机器学习-ff69b4.svg">
        </a>
   <a href="">
        <img src="https://img.shields.io/badge/未完-更新中-orange.svg">
        </a>
   <a href="https://github.com/yhangf/ML-NOTE">
    <img src="https://img.shields.io/github/stars/yhangf/ML-NOTE.svg?style=social&label=Star">
        </a>
    <a href="https://github.com/yhangf/ML-NOTE">
    <img src="https://img.shields.io/github/forks/yhangf/ML-NOTE.svg?style=social&label=Fork">
        </a>

</p>

慢慢整理所学的和机器学习相关的知识，并根据自己所理解的样子叙述出来。笔记中难免会出现一些错误，希望读者能够自己辨证着去看待，如果能把你的一些建议反馈给我的话那是再好不过的，所有文章也可以在[知乎专栏](https://zhuanlan.zhihu.com/jiqixuexi)阅读，相关代码实现可以参考我写的另一个微机器学习框架[**mimose**](https://github.com/yhangf/mimose)。

#### 笔记内容

- [x] 线性回归与最小二乘法  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/线性回归与最小二乘法.pdf) | [知乎](https://zhuanlan.zhihu.com/p/36910496)]
- [x] 逻辑回归算法  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/逻辑回归算法.pdf) | [知乎](https://zhuanlan.zhihu.com/p/37020923)]
- [x] 感知机算法  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/感知机算法.pdf) | [知乎](https://zhuanlan.zhihu.com/p/37134548)]
- [x] 高斯判别分析  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/高斯判别分析.pdf) | [知乎](https://zhuanlan.zhihu.com/p/38269530)]
- [x] 支持向量机(上篇)  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/支持向量机(上篇).pdf) | [知乎](https://zhuanlan.zhihu.com/p/39219534)]
- [x] 支持向量机(下篇)  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/支持向量机(下篇).pdf) | [知乎](https://zhuanlan.zhihu.com/p/47806581)]
- [x] EM算法  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/EM算法.pdf) | [知乎](https://zhuanlan.zhihu.com/p/39490840)]
- [x] 朴素贝叶斯算法  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/朴素贝叶斯算法.pdf) | [知乎](https://zhuanlan.zhihu.com/p/40246165)]
- [x] 反向传播算法  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/反向传播算法.pdf) | [知乎](https://zhuanlan.zhihu.com/p/40761721)]
- [x] PCA算法  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/PCA算法.pdf) | [知乎](https://zhuanlan.zhihu.com/p/46671639)]
- [x] 核函数粗浅的理解  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/核函数粗浅的理解.pdf) | [知乎](https://zhuanlan.zhihu.com/p/47541349)]
- [x] L1和L2正则化的概率解释  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/L1和L2正则化的概率解释.pdf) | [知乎](https://zhuanlan.zhihu.com/p/56185913)]
- [x] 某些特殊概率分布之间的相互变换  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/某些特殊概率分布之间的相互变换.pdf) | [知乎](https://zhuanlan.zhihu.com/p/56703117)]
- [x] 高维数据可视化之t-SNE算法  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/高维数据可视化之t-SNE算法.pdf) | [知乎](https://zhuanlan.zhihu.com/p/57937096)]
- [x] Word2Vec算法梳理  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/word2vec算法梳理.pdf) | [知乎](https://zhuanlan.zhihu.com/p/58290018)]
- [x] GBDT算法原理梳理  [[pdf](https://github.com/yhangf/ML-NOTE/blob/master/pdf/GBDT算法原理梳理.pdf) | [知乎](https://zhuanlan.zhihu.com/p/59434537)]

